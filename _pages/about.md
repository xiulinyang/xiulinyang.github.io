---
permalink: /
title: "About"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hi! My name is Xiulin Yang and I'm currently a third-year PhD student in Computational Linguistics at <a href='https://www.georgetown.edu/' target ='_top'>Georgetown University</a>, advised by <a href='https://scholar.google.com/citations?hl=en&user=3cozMf4AAAAJ' target ='_top'>Professor Nathan Schneider</a>. At Georgetown, I also work closely with <a href='https://scholar.google.com/citations?user=5jzLBBwAAAAJ&hl=en' target ='_top'>Professor Ethan Wilcox</a> and <a href='https://scholar.google.com/citations?user=Grvf4zYAAAAJ&hl=en' target ='_top'>Professor Amir Zeldes</a>. I'm a member of <a href='http://nert.georgetown.edu/' target ='_top'>NERT</a> and <a href='https://github.com/picol-georgetown/wiki' target ='_top'>PICoL</a>.

Before that, I have been lucky to work with <a href = 'https://www.jyfindlay.com/' target ='_top'> Professor Jamie Findlay </a> and <a href = 'https://www.mod-langs.ox.ac.uk/people/hanne-eckhoff' target ='_top'> Professor Hanne Eckhoff </a> at Oxford,<a href='https://scholar.google.com/citations?user=yni3K9wAAAAJ&hl=en' target='_top'> Professor Alexander Koller </a> at Saarland and <a href = 'https://www.rug.nl/staff/johan.bos/cv?lang=en' target = '_top'> Professor Johan Bos</a> at Groningen.


I‚Äôm broadly interested in Computational Linguistics, Cognitive Science, NLP, and linguistic theories. I have worked and am working on the following areas:

- generalization of language models (To what extend can language models generalize from their training data?)

- inductive bias of language models and humans (What's the difference between human mind and language models? How can we make language models more human like by introducing such inductive bias?)

- learnability of natural languages (what makes some languages harder to learn to machines?)

- computational semantics (How to develop accurate and generalizable parsers? How can we incorporate meaning representation to downstream tasks?)

- neuro-symbolic NLP (How to incorporate linguistic information to NLP tasks?)

- targeted evaluation of language models (What do language models know about natural language we speak?)

When I'm not in front of the screen, you can find me bouldering/wall-climbing, reading (I'm a big fan of science fictions!), or swimming. 

# üî• News
- **05-2025** Gave a talk on Poverty of the Stimulus at TinLab, Boston University! üó£Ô∏è

- **05-2025** Received the Outstanding Reviewer Award for EMNLP 2025! ü•≥

- **05-2025** Our paper *Anything Goes? A Crosslinguistic Study of (Im)possible Language Learning in LMs* was accepted to ACL2025 main conference! Feel free to check it out. :)

- **04-2025** I gave a talk on impossible language learning at Learning and Development Lab, Georgetown University! 

- **12-2024** Our paper *Language Models at the Syntax-Semantics Interface: A Case Study of the Long-Distance Binding of Chinese Reflexive ziji* will be presented at COLING 2025!

- **09-2024** Our paper *Scope-enhanced Compositional Semantic Parsing for DRT* will be presented at EMNLP 2024!


# üìù Publications & Presentations 
- Min, J., **Yang, X.**, & Wein, S. (2025). When Does Meaning Backfire? Investigating the Role of AMRs in NLI. Under review
- **Yang, X.**, Ju, Z., Bu, L., Liu, Z., & Schneider, N. (2025). UD-English-CHILDES: A Collected Resource of Gold and Silver Universal Dependencies Trees for Child Language Interactions. Proceedings of the Workshop on Universal Dependencies (UDW) at the 2025 Syntax Fest.
- **Yang, X.**, Aoyama, T., Yao, Y., Wilcox, E. (2025). Anything Goes? A Crosslinguistic Study of (Im)possible Language Learning in LMs. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025, main long).
- **Yang, X.** (2025) Language Models at the Syntax-Semantics Interface: A Case Study of the Long-
Distance Binding of Chinese Reflexive ziji. Proceedings of the 31st International Conference on
Computational Linguistics.
- **Yang, X.**, Groschwitz, J., Koller, A., & Bos, J. (2024). Scope-enhanced Compositional Semantic Parsing for DRT. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing.
- **Yang, X.**, & Schneider, N. (2024). Are AMR Parsers Fooled by Relative Clauses? In Proceedings of the
Fifth International Workshop on Designing Meaning Representations (2024).
- Otto, C., Groschwitz, J., Koller, A., **Yang, X.**, & Donatelli, L. (2024). A corpus of German Abstract Meaning Representation (DeAMR). In Proceedings of the Thirteenth Language Resources and Evaluation Conference (2024).
- **Yang, X.**, Chen, J., van Eerden, A., Samin, A., & Bisazza, A. (2023). Slaapte or sliep? Extending neural- network simulations of English past tense learning to German and Dutch. In Proceedings of the 24th Nordic Conference of Computational Linguistics (NODALIDA 2023).
- **Yang, X.** (2022, July). The Ambiguous Binding of the Chinese Reflexive ziji: a Unified LFG Analysis [Poster presentation]. In Proceedings of the LFG‚Äô22 Conference, Groningen, the Netherlands. 
- **Yang, X.** (2022, June). Was Europeanization of Chinese Intensified from 1946 to 2003? [Poster Presentation]. LOT Summer School, Groningen, the Netherlands.

# üéñ Honors and Awards
- *08.2023,2024,2025* Merit-Based Graduate School Scholarship, Georgetown University.
- *07.2022* George Wolf Prize, The University of Oxford.
- *04.2021* Erasmus Mundus Language and Communication Program Scholarship, University of Groningen & Saarland University.
- *07.2020* Outstanding Graduate of Shandong University.
- *2018-2019* Scholarship for Outstanding Students of Shandong University (2017,2018,2019).
- *2018-2019* Merit Student of School of Foreign Languages Shandong University (2017,2018,2019).
- *09.2018* Shandong Radio & TV Station Scholarship, Shandong University.
- *09.2018* Overseas Study Scholarship, Shandong University.

# üìñ Educations
- *08.2023 - present* Georgetown University, PhD in Computational Linguistics. 
- *09.2021 - 11.2023* The University of Groningen and Saarland University, Joint Master in Language and Communication Technologies.
- *10.2020 - 07.2021* University of Oxford, Master in Linguistics, Philology and Phonetics.
- *09.2016 - 07.2020* Shandong University, BA in English.

# CV
You can find my CV <a href = 'https://drive.google.com/file/d/1BzRoihSYTMqXGSVEFVEBYpnac7oAKzil/view?usp=sharing' target = '_top'> here</a>.

